{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATS Python project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m40 packages\u001b[0m \u001b[2min 0.66ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m6 packages\u001b[0m \u001b[2min 0.01ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomislav Dukez\n",
      "\n",
      "Full Stack Developer – Django, Flask, FastAPI, Node.js, Python,  JavaScript, ML with Python, Tableau\n",
      "\n",
      "LinkedIn | GitHub | Website\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Zahna, Germany\n",
      "\n",
      "tomdu3@ymail.com\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I am a Full-stack Software Development with a specialization in Predictive Analytics from the Code Institute, Dublin.\n",
      "\n",
      "Technologies and Languages\n",
      "\n",
      "Languages: HTML, CSS, JavaScript, Python, TypeScript, C, SQL\n",
      "\n",
      "Technologies: NodeJS, ExpressJS, Flask, Django, Bootstrap, Tailwind, Automated Testing in Python and JS: Unittest, Pytest, Jest; SQLite3, PostgreSQL, jQuery, React; Data Science and Machine Learning: NumPy, Pandas, Matplotlib, Seaborn, Plotly, Scikit-Learn, TensorFlow, Streamlit, Jupyter Notebook, Tableau, Excel, Git, GitHub\n",
      "\n",
      "Other: Heroku, Data Structures and Algorithms, Agile Development, UI/UX Design, Software Project Management, Docker.\n",
      "\n",
      "\n",
      "\n",
      "I have experience as a University Lecturer, diplomat, and Officer-in-Charge in Public Administration. I’m skilled in communication and problem-solving, with a strong interest in back-end development and coding tutoring. I’m especially passionate about data analysis and database management.\n",
      "\n",
      "\n",
      "\n",
      "Projects\n",
      "\n",
      "Hungry Hippo (Code | View Site)\n",
      "\n",
      "Hungry Hippo is a Full Stack Web Application developed during the 50th Voyage organized by Chingu. This project simulates an online food delivery service, providing users with a seamless experience to browse and order food from various restaurants. Technologies Used: JavaScript, TypeScript, React, Tailwind, NodeJS, Express.js, PostgreSQL.\n",
      "\n",
      "User-friendly interface for browsing food options\n",
      "\n",
      "Real-time order processing functionality\n",
      "\n",
      "Restaurant selection and menu display\n",
      "\n",
      "Responsive design for optimal mobile and desktop usage\n",
      "\n",
      "Secure authentication and user account management  \n",
      "\n",
      "Brain Tumor Detector (Code | View Site)\n",
      "\n",
      "A Machine Learning project developed using Python, TensorFlow, and various libraries like NumPy, Matplotlib, and Seaborn, aimed at distinguishing between healthy brain MRI scans and those with tumors. This tool features a user-friendly Streamlit Dashboard that allows clients to upload MRI brain scans for tumor diagnosis predictions.\n",
      "\n",
      "Streamlit Dashboard for easy uploads\n",
      "\n",
      "Utilizes TensorFlow for machine learning-based predictions\n",
      "\n",
      "Incorporates data visualization with Matplotlib, Seaborn, and Plotly\n",
      "\n",
      "Offers advanced tuning with Keras Tuner and Scikit-Learn\n",
      "\n",
      "\n",
      "\n",
      "Books for Life (Code | View Site)\n",
      "\n",
      "Books for Life is a Full Stack website designed as a platform for book enthusiasts to share and discover their favorite books. Technologies Used: Python, HTML, CSS, JavaScript, jQuery, Django, Bootstrap, PostgreSQL.\n",
      "\n",
      "User registration and authentication\n",
      "\n",
      "Book submission and review system\n",
      "\n",
      "Search and filter functionality for easy discovery\n",
      "\n",
      "Responsive design for seamless access on various devices\n",
      "\n",
      "Community-driven platform fostering interaction among book lovers  \n",
      "\n",
      "Out and About (Code | View Site)\n",
      "\n",
      "Out and About is a winning project from the Code Institute Hackathon that showcases significant events throughout history related to the LGBTQ+ community worldwide. The site features an interactive globe, allowing users to rotate, zoom, and click on countries marked with pride flags to learn about related events. Technologies Used: Python, Flask, PostgreSQL, HTML, CSS, TailwindCSS, JavaScript.\n",
      "\n",
      "Interactive globe feature for exploring global events\n",
      "\n",
      "Country-specific information accessible via pride flag markers\n",
      "\n",
      "User-friendly design to enhance engagement and learning\n",
      "\n",
      "Comprehensive timeline of LGBTQ+ historical events\n",
      "\n",
      "Responsive interface for various devices  \n",
      "\n",
      "\n",
      "\n",
      "Smiley Memories (Code | View Site)\n",
      "\n",
      "Smiley’s Memories is a responsive and interactive front-end memory game featuring a fun Smiley Emoji theme. This project was completed as part of the Code Institute’s Full-Stack Web Development diploma program, showcasing skills in web development and user engagement. Technologies Used: HTML5, CSS3, and Vanilla JavaScript.\n",
      "\n",
      "Engaging and playful Smiley Emoji-themed design\n",
      "\n",
      "Interactive gameplay designed for memory enhancement\n",
      "\n",
      "Fully responsive layout ensuring compatibility across devices\n",
      "\n",
      "Simple and intuitive user interface for all ages\n",
      "\n",
      "Smooth animations and interactive feedback for game actions  \n",
      "\n",
      "\n",
      "\n",
      "Experience\n",
      "\n",
      "\n",
      "\n",
      "Chingu - Voyage 50: Project Owner - Backend Lead (NodeJS, ExpressJS, TypeScript, PostgreSQL)\n",
      "\n",
      "July – August 2024\n",
      "\n",
      "Led the backend development of Hungry Hippo, a full-stack food delivery web application. \n",
      "\n",
      "Utilized Node.js, Express, and PostgreSQL to design and implement robust APIs that facilitated seamless order management and tracking.\n",
      "\n",
      "Collaborated with a team of frontend developers using React, Tailwind, and TypeScript to ensure an optimal user experience.\n",
      "\n",
      "Successfully managed project timelines and deliverables within an agile environment.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "London School of Informatics - Data Analyst, Associate (Python, Jupyter Notebook, Tableau, TensorFlow, Scikit-Learn, Pandas, Matplotlib)\n",
      "\n",
      "April – June 2024\n",
      "\n",
      "Team Lead in performing research and analysis to assist ERP (Enterprise Resource Planning) companies in staying ahead of their competition.\n",
      "\n",
      "Compiled data using data visualization (Excel) by working with senior Data analysts to get meaningful insights that improve organizational processes.\n",
      "\n",
      "Participated in in-house workshops to improve industry knowledge\n",
      "\n",
      "\n",
      "\n",
      "Freelance - Junior Full-Stack Developer - Coding Tutor\n",
      "\n",
      "2023 - Present\n",
      "\n",
      "Providing personalized tutoring in Python, Front End (HTML, CSS, JavaScript, jQuery), and Back End (Django, Flask, NodeJS) technologies to help individuals and groups gain practical coding skills and solve programming challenges. My unique blend of technical expertise and teaching ability enables me to facilitate effective learning experiences for my students.\n",
      "\n",
      "\n",
      "\n",
      "\t\t\n",
      "\n",
      "\t\tEducation\tInterests\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "Data Science Training Program at London School of Informatics, UK\n",
      "\n",
      "October 2023 - February 2024\n",
      "\n",
      "\tData Science Fundamentals\n",
      "\n",
      "\tPython Data Science libraries and tools\n",
      "\n",
      "\tMS Excel, Tableau, Intro to PowerBI\n",
      "\n",
      "\n",
      "\n",
      "Diploma in Full Stack Software Development with Specialization in Predictive Analytics, at Code Institute, Dublin, Ireland\n",
      "\n",
      "October 2022 – February 2024\n",
      "\n",
      "(Credit Rated by University of West of Scotland)\n",
      "\n",
      "\tHTML, CSS, JavaScript\n",
      "\n",
      "\tPython\n",
      "\n",
      "\tPython Backend (Flask, Django)\n",
      "\n",
      "\tSQL, SQLite3, PostgreSQL\n",
      "\n",
      "\tUnit Testing (Jest, Untittest, Pytest)\n",
      "\n",
      "\tGit / GitHub\n",
      "\n",
      "\tMachine Learning Libraries and Tools: NumPy, Pandas, TensorFlow, Matplotlib, Scikit-Learn, Streamlit\n",
      "\n",
      "\n",
      "\n",
      "PhD in Law, Canon Law \n",
      "\n",
      "Faculty of Canon Law, Pontifical Lateran University, Rome, Italy (2010-2011)\n",
      "\n",
      "\n",
      "\n",
      "BSc Hons in Theology, Humanities\n",
      "\n",
      "Faculty of Theology in Zagreb and in Dakovo, University of Zagreb, Croatia (1998-2003)\n",
      "\n",
      "\n",
      "Coding: I’m a dedicated coder and Linux user with a strong interest in Data Analytics, Machine Learning, and Full Stack Software Development (BE Heavy).\n",
      "\n",
      "\n",
      "\n",
      "Education: I enjoy educating others in coding and working in educational programs to help individuals learn and grow in their programming skills.\n",
      "\n",
      "\n",
      "\n",
      "Other Interests: I have a love for math, classical music, literature (especially poetry), cycling, and traveling, which enrich my perspective and creativity.\n",
      "\n",
      "\n",
      "\n",
      "Language Skills: I am a native Croatian speaker, fluent in Italian and English, with beginner proficiency in German and French.\n"
     ]
    }
   ],
   "source": [
    "import docx2txt\n",
    "resume = docx2txt.process('./data/Tomislav Dukez - CV - Nov 2024.docx')  # change path to your cv\n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mthree helps organisations succeed by building job-ready teams with the most in-demand skills.\n",
      "\n",
      "They are looking for a talented Python Developer to join a global FX Options Technology team with one of the leading Global Investment Banks. Based in London, you will be part of a collaborative and innovative environment, supporting the FX Options Trading business. The team focuses on developing cutting-edge solutions while transitioning from legacy systems, and this is an exciting opportunity to work on high-impact projects in a fast-paced front office environment.\n",
      "\n",
      "\n",
      "Key Responsibilities\n",
      "\n",
      "    Develop, deploy, and support front-office applications for Pricing, eTrading, Market Making, and Trade Booking.\n",
      "    Collaborate closely with brokers, external clients, and business partners to expand and improve electronic offerings.\n",
      "    Ensure system integration with upstream trade execution platforms and enhance systems to meet regulatory requirements (MiFID II, UMR, IMM).\n",
      "    Liaise with teams across Trading, Sales, Market Risk, and Operations to gather requirements and implement key changes.\n",
      "    Support and develop market-making tools within FX, contributing to system simplification and meeting desk needs.\n",
      "    Be part of a high-performance team delivering top-tier technology solutions to the FX Options business.\n",
      "\n",
      "\n",
      "Skills & Qualifications\n",
      "\n",
      "    Strong development experience in Python.\n",
      "    Experience or interest in agile methodologies (XP, SCRUM, Kanban) and continuous integration.\n",
      "    A degree in Computer Science, Physics, Engineering, or Mathematics.\n",
      "    Excellent problem-solving, analytical skills, and understanding of algorithms, data structures, and design patterns.\n",
      "    Familiarity with messaging middleware, TCP/IP networking, and large-scale distributed systems.\n",
      "    Strong communication skills and ability to collaborate with business stakeholders.\n",
      "    Interest or experience in financial products (FX, Derivatives, Options) and familiarity with FIX Protocol, FpML, or similar financial models is a plus.\n"
     ]
    }
   ],
   "source": [
    "# open file './data/job-descr.txt' and assign it to a variable job_descr\n",
    "with open('./data/job-descr.txt', 'r') as f:  # I used txt for simplicity, but it can be done in the same manner as for the cv\n",
    "    job_descr = f.read()\n",
    "\n",
    "print(job_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store data in a list\n",
    "data = [resume, job_descr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m40 packages\u001b[0m \u001b[2min 0.55ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m6 packages\u001b[0m \u001b[2min 0.01ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 630 stored elements and shape (2, 581)>\n",
      "  Coords\tValues\n",
      "  (0, 518)\t1\n",
      "  (0, 141)\t1\n",
      "  (0, 212)\t9\n",
      "  (0, 475)\t9\n",
      "  (0, 124)\t2\n",
      "  (0, 137)\t5\n",
      "  (0, 199)\t5\n",
      "  (0, 187)\t1\n",
      "  (0, 348)\t2\n",
      "  (0, 281)\t4\n",
      "  (0, 417)\t12\n",
      "  (0, 276)\t8\n",
      "  (0, 336)\t1\n",
      "  (0, 569)\t13\n",
      "  (0, 489)\t4\n",
      "  (0, 308)\t1\n",
      "  (0, 226)\t3\n",
      "  (0, 563)\t2\n",
      "  (0, 579)\t1\n",
      "  (0, 223)\t1\n",
      "  (0, 517)\t1\n",
      "  (0, 576)\t1\n",
      "  (0, 83)\t1\n",
      "  (0, 26)\t2\n",
      "  (0, 466)\t4\n",
      "  :\t:\n",
      "  (1, 155)\t1\n",
      "  (1, 323)\t1\n",
      "  (1, 171)\t1\n",
      "  (1, 32)\t1\n",
      "  (1, 538)\t1\n",
      "  (1, 380)\t1\n",
      "  (1, 185)\t2\n",
      "  (1, 332)\t1\n",
      "  (1, 334)\t1\n",
      "  (1, 493)\t1\n",
      "  (1, 271)\t1\n",
      "  (1, 347)\t1\n",
      "  (1, 292)\t1\n",
      "  (1, 439)\t1\n",
      "  (1, 136)\t1\n",
      "  (1, 476)\t1\n",
      "  (1, 195)\t2\n",
      "  (1, 406)\t1\n",
      "  (1, 116)\t1\n",
      "  (1, 196)\t1\n",
      "  (1, 413)\t1\n",
      "  (1, 205)\t1\n",
      "  (1, 457)\t1\n",
      "  (1, 338)\t1\n",
      "  (1, 392)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.64136657]\n",
      " [0.64136657 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(count_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "match = cosine_similarity(count_matrix)[0][1]\n",
    "match = round(match*100)\n",
    "print(f'{match}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keywords identifications and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched keywords: ['design', 'global', 'london', 'developer', 'strong', 'structures', 'implement', 'agile', 'communication', 'improve', 'ensure', 'algorithms', 'development', 'environment', 'team', 'data', 'options', 'science', 'python', 'enhance', 'clients', 'problemsolving', 'tools', 'ability', 'projects']\n",
      "Unmatched keywords: ['umr', 'supporting', 'external', 'ii', 'fpml', 'qualifications', 'liaise', 'xp', 'applications', 'continuous', 'largescale', 'collaborative', 'solutions', 'derivatives', 'models', 'brokers', 'physics', 'succeed', 'building', 'kanban', 'cuttingedge', 'key', 'plus', 'systems', 'transitioning', 'highperformance', 'upstream', 'mifid', 'focuses', 'technology', 'execution', 'tcpip', 'mathematics', 'messaging', 'join', 'investment', 'familiarity', 'leading', 'develop', 'market', 'networking', 'protocol', 'delivering', 'computer', 'collaborate', 'analytical', 'marketmaking', 'indemand', 'helps', 'business', 'financial', 'organisations', 'degree', 'support', 'operations', 'exciting', 'platforms', 'excellent', 'trade', 'integration', 'gather', 'fastpaced', 'similar', 'partners', 'needs', 'patterns', 'fix', 'understanding', 'banks', 'deploy', 'innovative', 'changes', 'fx', 'teams', 'products', 'jobready', 'desk', 'regulatory', 'engineering', 'talented', 'pricing', 'looking', 'toptier', 'methodologies', 'electronic', 'stakeholders', 'making', 'highimpact', 'responsibilities', 'contributing', 'mthree', 'trading', 'based', 'developing', 'legacy', 'etrading', 'sales', 'office', 'distributed', 'expand', 'meeting', 'closely', 'middleware', 'booking', 'risk', 'offerings', 'meet', 'imm', 'scrum', 'simplification', 'frontoffice', 'opportunity']\n"
     ]
    }
   ],
   "source": [
    "# import string, and stop words in english\n",
    "import string\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "english_stop_words = set(ENGLISH_STOP_WORDS)\n",
    "# add to the list some words that are not stop words but are not important for resume matching\n",
    "english_stop_words.add(\"experience\")\n",
    "english_stop_words.add(\"work\")\n",
    "english_stop_words.add(\"skills\")\n",
    "english_stop_words.add(\"skill\")\n",
    "english_stop_words.add(\"requirements\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Convert text to lowercase, remove punctuation,\n",
    "    and filter out common English stop words.\n",
    "    \"\"\"\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    # remove punctuation using str.translate\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # split text into tokens/words\n",
    "    tokens = text.split()\n",
    "    # filter stop words\n",
    "    tokens = [word for word in tokens if word not in english_stop_words]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# Preprocess job description and resume texts\n",
    "job_tokens = preprocess_text(job_descr)\n",
    "resume_tokens = preprocess_text(resume)\n",
    "\n",
    "# Convert job description tokens into a set of unique keywords\n",
    "job_keywords = set(job_tokens)\n",
    "\n",
    "# Prepare lists to store matched and unmatched keywords\n",
    "matched_keywords = []\n",
    "unmatched_keywords = []\n",
    "\n",
    "for keyword in job_keywords:\n",
    "    if keyword in resume_tokens:\n",
    "        matched_keywords.append(keyword)\n",
    "    else:\n",
    "        unmatched_keywords.append(keyword)\n",
    "\n",
    "print(\"Matched keywords:\", matched_keywords)\n",
    "print(\"Unmatched keywords:\", unmatched_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['umr',\n",
       " 'supporting',\n",
       " 'external',\n",
       " 'ii',\n",
       " 'fpml',\n",
       " 'qualifications',\n",
       " 'liaise',\n",
       " 'xp',\n",
       " 'applications',\n",
       " 'continuous',\n",
       " 'largescale',\n",
       " 'collaborative',\n",
       " 'solutions',\n",
       " 'derivatives',\n",
       " 'models',\n",
       " 'brokers',\n",
       " 'physics',\n",
       " 'succeed',\n",
       " 'building',\n",
       " 'kanban',\n",
       " 'cuttingedge',\n",
       " 'key',\n",
       " 'plus',\n",
       " 'systems',\n",
       " 'transitioning',\n",
       " 'highperformance',\n",
       " 'upstream',\n",
       " 'mifid',\n",
       " 'focuses',\n",
       " 'technology',\n",
       " 'execution',\n",
       " 'tcpip',\n",
       " 'mathematics',\n",
       " 'messaging',\n",
       " 'join',\n",
       " 'investment',\n",
       " 'familiarity',\n",
       " 'leading',\n",
       " 'develop',\n",
       " 'market',\n",
       " 'networking',\n",
       " 'protocol',\n",
       " 'delivering',\n",
       " 'computer',\n",
       " 'collaborate',\n",
       " 'analytical',\n",
       " 'marketmaking',\n",
       " 'indemand',\n",
       " 'helps',\n",
       " 'business',\n",
       " 'financial',\n",
       " 'organisations',\n",
       " 'degree',\n",
       " 'support',\n",
       " 'operations',\n",
       " 'exciting',\n",
       " 'platforms',\n",
       " 'excellent',\n",
       " 'trade',\n",
       " 'integration',\n",
       " 'gather',\n",
       " 'fastpaced',\n",
       " 'similar',\n",
       " 'partners',\n",
       " 'needs',\n",
       " 'patterns',\n",
       " 'fix',\n",
       " 'understanding',\n",
       " 'banks',\n",
       " 'deploy',\n",
       " 'innovative',\n",
       " 'changes',\n",
       " 'fx',\n",
       " 'teams',\n",
       " 'products',\n",
       " 'jobready',\n",
       " 'desk',\n",
       " 'regulatory',\n",
       " 'engineering',\n",
       " 'talented',\n",
       " 'pricing',\n",
       " 'looking',\n",
       " 'toptier',\n",
       " 'methodologies',\n",
       " 'electronic',\n",
       " 'stakeholders',\n",
       " 'making',\n",
       " 'highimpact',\n",
       " 'responsibilities',\n",
       " 'contributing',\n",
       " 'mthree',\n",
       " 'trading',\n",
       " 'based',\n",
       " 'developing',\n",
       " 'legacy',\n",
       " 'etrading',\n",
       " 'sales',\n",
       " 'office',\n",
       " 'distributed',\n",
       " 'expand',\n",
       " 'meeting',\n",
       " 'closely',\n",
       " 'middleware',\n",
       " 'booking',\n",
       " 'risk',\n",
       " 'offerings',\n",
       " 'meet',\n",
       " 'imm',\n",
       " 'scrum',\n",
       " 'simplification',\n",
       " 'frontoffice',\n",
       " 'opportunity']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
